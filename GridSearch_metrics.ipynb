{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wagner1986/PapyrusTech/blob/main/ManyLocalFeatureMatcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7qDTBLJ0voC",
        "outputId": "edd54f30-ee98-4aba-b487-789dcc805de3"
      },
      "outputs": [],
      "source": [
        "# !pip install kornia\n",
        "# !pip install kornia_moons --no-deps\n",
        "#!pip install kornia\n",
        "#!pip install kornia_moons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ccx4czDmT1ZW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplo de Tempo: 0.04948057100045844 segundos\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from kornia.utils import tensor_to_image\n",
        "from typing import Dict, Tuple, List\n",
        "from kornia.feature import LocalFeatureMatcher, GFTTAffNetHardNet, DescriptorMatcher,KeyNetHardNet,SIFTFeatureScaleSpace,SIFTFeature,HesAffNetHardNet\n",
        "from kornia.feature import LocalFeature, LAFDescriptor, MultiResolutionDetector,ScaleSpaceDetector, SOSNet,HardNet\n",
        "from kornia.feature import CornerHarris, CornerGFTT, PassLAF, LAFOrienter, LAFAffNetShapeEstimator\n",
        "\n",
        "from utils import (\n",
        "    free_memory,  # Função para liberar memória coletando objetos não utilizados e esvaziando o cache da GPU se disponível\n",
        "    evaluate_matches,  # Função para avaliar correspondências entre conjuntos de referência e inspeção, retornando verdadeiros positivos, falsos positivos e falsos negativos\n",
        "    set_seed,  # Função para configurar a semente e garantir a reprodutibilidade dos experimentos\n",
        "    medir_tempo,  # Context Manager para medir e imprimir o tempo de execução de um bloco de código\n",
        "    plot_image_with_keypoints,  # Função para plotar uma imagem e seus keypoints\n",
        "    plot_tensor,  # Função para plotar um tensor PyTorch como uma imagem\n",
        "    print_table,  # Função para imprimir uma matriz em formato tabular\n",
        "    MyDrawMatcher  # Classe para desenhar correspondências entre imagens utilizando Kornia\n",
        ")\n",
        "set_seed(42)\n",
        "\n",
        "# Importa classes e módulos do pacote 'experiments'\n",
        "from experiments import (\n",
        "    PreprocessPipeline,  # Classe que implementa a interface IPreprocessor para pré-processamento de imagens, incluindo normalização, redimensionamento e conversão para escala de cinza\n",
        "    DelaunayGraph,  # Classe que implementa a interface IGlobalFeatureStructurer para estruturar features globais em um grafo usando triangulação Delaunay\n",
        "    FloydWarshall,  # Classe que implementa a interface IGlobalMatcher para comparar similaridade global de features em grafos usando o algoritmo de Floyd-Warshall\n",
        "    WoodsDataset  \n",
        ")\n",
        "\n",
        "# Exemplo de uso do Context Manager para medir o tempo de execução de um bloco de código\n",
        "with medir_tempo(\"Exemplo de Tempo\"):\n",
        "    # Loop para realizar um milhão de iterações como exemplo\n",
        "    for i in range(1_000_000):\n",
        "        pass  # Placeholder para o código a ser executado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xC3mt__LJNgM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device cpu\n",
            "Total de elementos no dataset: 6148 total batch: 62\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class ImageComparisonPipeline:\n",
        "    # __slots__ = ['preprocessor', 'local_feature', 'descriptor_matcher', 'global_structurer', 'global_matcher']\n",
        "\n",
        "    def __init__(self, preprocessor=None, local_feature: LocalFeature = None, descriptor_matcher: DescriptorMatcher = None, global_structurer=None, global_matcher=None):\n",
        "        self.preprocessor = preprocessor\n",
        "        self.local_feature = local_feature\n",
        "        self.descriptor_matcher_ablation = descriptor_matcher\n",
        "        self.descriptor_matcher_fixed=  DescriptorMatcher('snn', self.descriptor_matcher_ablation.th)\n",
        "        self.global_structurer = global_structurer\n",
        "        self.global_matcher = global_matcher\n",
        "        \n",
        "\n",
        "    def process_global(self, out,images,is_plot=False):\n",
        "        matricesAdj = []\n",
        "\n",
        "        for index in (0, 1):\n",
        "            pts = out[f'keypoints{index}'][out['matches'][:, index]].cpu().detach().numpy()\n",
        "            desc = out[f'descriptors{index}'][out['matches'][:, index]].cpu().detach().numpy()\n",
        "            matrixAdj, _ = self.global_structurer(pts, desc)\n",
        "            matricesAdj.append(matrixAdj)\n",
        "            if is_plot:\n",
        "                img = tensor_to_image(images[index].squeeze())\n",
        "                DelaunayGraph.plot_delaunay(pts,_,img=img)\n",
        "        return matricesAdj\n",
        "\n",
        "    def run(self, inspection_images: torch.Tensor, reference_images: torch.Tensor,threshold=0.1, log=None,device=torch.device('cpu')) -> Dict[Tuple[int, int], float]:\n",
        "        if not all([self.preprocessor, self.local_feature, self.descriptor_matcher_ablation, self.global_structurer, self.global_matcher]):\n",
        "            raise ValueError(\"Pipeline components are not fully set.\")\n",
        "        n,m = inspection_images.shape[0],reference_images.shape[0]\n",
        "        scores = np.zeros((n, m))\n",
        "        count_match = np.zeros((n, m))\n",
        "        myDraw =MyDrawMatcher()\n",
        "        cache_reference = {}\n",
        "       \n",
        "        for i_index, i_image in enumerate(inspection_images):\n",
        "            lafs0, responses0, descriptors0 = self.local_feature(i_image[:1][None])\n",
        "            for r_index, r_image in enumerate(reference_images):\n",
        "                if r_index not in cache_reference:\n",
        "                    lafs1, responses1, descriptors1 = self.local_feature(r_image[:1][None])\n",
        "                    cache_reference[r_index] = (lafs1, responses1, descriptors1)\n",
        "                else:\n",
        "                    lafs1, responses1, descriptors1 = cache_reference[r_index]\n",
        "            \n",
        "                distance_ablation, matches_ablation = self.descriptor_matcher_ablation(descriptors0[0], descriptors1[0])# ablation\n",
        "                distance, matches = self.descriptor_matcher_fixed(descriptors0[0], descriptors1[0])\n",
        "                out = {\n",
        "                \"keypoints0\": lafs0[0, :, :, 2].data,#[N, 2])\n",
        "                \"keypoints1\": lafs1[0, :, :, 2].data,#[N, 2])\n",
        "                \"lafs0\": lafs0,#[1, N, 2, 3]\n",
        "                \"lafs1\": lafs1,#[1, N, 2, 3]\n",
        "                \"descriptors0\": descriptors0[0],#[N, 128])\n",
        "                \"descriptors1\": descriptors1[0],#[N, 128])\n",
        "                \"matches\": matches,#[M, 2])\n",
        "                }\n",
        "\n",
        "                \n",
        "                #ignora quando existem poucos pontos, pois diminui a confianca(global)\n",
        "                if(matches.shape[0]>=3):\n",
        "                    try:\n",
        "                        is_plot= False\n",
        "                        # if  i_index==3 and r_index in [3,12]:\n",
        "                        #     print(\"({},{})=>*\".format(i_index,r_index))\n",
        "                        #     is_plot= True\n",
        "                        matricesAdj = self.process_global(out,images=[i_image,r_image],is_plot=is_plot)\n",
        "                        score = self.global_matcher(*matricesAdj, threshold=threshold)\n",
        "                    except Exception as e:\n",
        "                        score = 0   # possui poucos pontos     \n",
        "                else:\n",
        "                   score = 0    \n",
        "                \n",
        "                #ignora quando existem poucos pontos, pois diminui a confianca(local)\n",
        "                num_match = matches_ablation.shape[0]  \n",
        "                if num_match<8:\n",
        "                    num_match= 0\n",
        "                             \n",
        "                # if log is not None and log in ('DEBUG') and i_index == r_index and i_index%20==0:\n",
        "                if log is not None and log in ('DEBUG') and ( i_index==3 and r_index in [3,12]):\n",
        "                    print(i_index,r_index ,out['keypoints0'].shape,out['descriptors0'].shape,out['matches'].shape,)\n",
        "                    temp = out.copy()\n",
        "                    temp['matches']=matches_ablation\n",
        "                    myDraw(i_image.cpu(), r_image.cpu(),temp)\n",
        "\n",
        "                count_match[i_index, r_index] = num_match # avaliacao pelo quantidade matching\n",
        "                scores[i_index, r_index] = score # avaliacao pela correspondencia local+global\n",
        "\n",
        "        if log is not None and log in ('INFO'):\n",
        "            print_table(count_match)\n",
        "            print(\"count_match : \",evaluate_matches(count_match,8))\n",
        "            print_table(scores)\n",
        "            print(\"scores : \",evaluate_matches(scores,8))\n",
        "\n",
        "        return count_match,scores\n",
        "\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import kornia.augmentation as KA\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "transform_original = transforms.Compose([\n",
        "    transforms.Resize((180, 180)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device',device)\n",
        "someDataset = datasets.Flowers102(root='./data', split='test', download=True,transform=transform_original)\n",
        "# someDataset = WoodsDataset(root='./data/woods/', train=True,transform=transform_original)\n",
        "# Encontre o primeiro número par abaixo de total_size\n",
        "total_size = len(someDataset)\n",
        "if total_size % 2 != 0:\n",
        "    total_size -= 1\n",
        "indices = np.arange(total_size)\n",
        "subset = Subset(someDataset, indices)\n",
        "\n",
        "some_loader = DataLoader(subset, batch_size=100, shuffle=True,)\n",
        "total_elements = len(some_loader.dataset)\n",
        "total_batches = len(some_loader)\n",
        "print(f'Total de elementos no dataset: {total_elements} total batch: {total_batches}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from kornia.feature import LocalFeature, LAFDescriptor, MultiResolutionDetector,SOSNet\n",
        "from kornia.feature import CornerGFTT, PassLAF, LAFOrienter, LAFAffNetShapeEstimator\n",
        "from kornia.feature.scale_space_detector import get_default_detector_config\n",
        "# Assuming SOSNet can be correctly imported as shown before; adjust if needed.\n",
        "\n",
        "    \n",
        "class GFTTFeatureSosNet(LocalFeature): #0.9    |   0.005\n",
        "    \"\"\"Convenience module, which implements GFTT detector + SOSNet descriptor.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_features: int = 200,\n",
        "        upright: bool = False,\n",
        "        device: torch.device = torch.device(\"cpu\"),\n",
        "        config: dict = None,\n",
        "    ) -> None:\n",
        "        if config is None:\n",
        "            config = get_default_detector_config()\n",
        "        detector = MultiResolutionDetector(\n",
        "            CornerGFTT(),\n",
        "            num_features,\n",
        "            config,\n",
        "            ori_module=PassLAF() if upright else LAFOrienter(19),\n",
        "            aff_module=LAFAffNetShapeEstimator(preserve_orientation=upright).eval(),  # Usa `upright` para definir `preserve_orientation`\n",
        "        ).to(device)\n",
        "\n",
        "        # Initialize your descriptor (e.g., SOSNet) as before\n",
        "        # Example with SOSNet - replace with actual initialization if different\n",
        "        sosnet32 = SOSNet(pretrained=True)  # Placeholder; adjust according to actual SOSNet import\n",
        "        sosnet32 = sosnet32.to(device).eval()\n",
        "\n",
        "        descriptor = LAFDescriptor(sosnet32, patch_size=32, grayscale_descriptor=True).to(device)\n",
        "\n",
        "        super().__init__(detector, descriptor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "pp = PreprocessPipeline()\n",
        "delaunayG = DelaunayGraph()\n",
        "floyd = FloydWarshall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device  cpu\n",
            "{'params': {'num_features': 30, 'feature_local_class': 'GFTTAffNetHardNet', 'distance': 0.9, 'threshold': 0.5}, 'matches': (2701, 441, 373), 'scores': (2894, 406, 180)}\n",
            "Tempo de execução: 1272.9440295010008 segundos\n",
            "{'params': {'num_features': 30, 'feature_local_class': 'GFTTFeatureSosNet', 'distance': 0.9, 'threshold': 0.5}, 'matches': (2746, 346, 328), 'scores': (2908, 161, 166)}\n",
            "Tempo de execução: 1163.2768958650013 segundos\n",
            "{'params': {'num_features': 30, 'feature_local_class': 'KeyNetHardNet', 'distance': 0.9, 'threshold': 0.5}, 'matches': (2053, 262, 1021), 'scores': (2417, 45, 657)}\n",
            "Tempo de execução: 1421.9091580679997 segundos\n",
            "{'params': {'num_features': 30, 'feature_local_class': 'HesAffNetHardNet', 'distance': 0.9, 'threshold': 0.5}, 'matches': (2627, 451, 447), 'scores': (2858, 382, 216)}\n",
            "Tempo de execução: 1064.6280547570022 segundos\n",
            "{'params': {'num_features': 30, 'feature_local_class': 'SIFTFeature', 'distance': 0.9, 'threshold': 0.5}, 'matches': (2608, 1696, 466), 'scores': (2891, 1240, 183)}\n",
            "Tempo de execução: 1029.6100386700018 segundos\n",
            "{'params': {'num_features': 30, 'feature_local_class': 'SIFTFeatureScaleSpace', 'distance': 0.9, 'threshold': 0.5}, 'matches': (2447, 3061, 627), 'scores': (2826, 3028, 248)}\n",
            "Tempo de execução: 1718.9097270429993 segundos\n",
            "Parâmetros: {'num_features': 30, 'feature_local_class': 'GFTTAffNetHardNet', 'distance': 0.9, 'threshold': 0.5}\n",
            "Matches: (2701, 441, 373)\n",
            "Scores: (2894, 406, 180)\n",
            "Parâmetros: {'num_features': 30, 'feature_local_class': 'GFTTFeatureSosNet', 'distance': 0.9, 'threshold': 0.5}\n",
            "Matches: (2746, 346, 328)\n",
            "Scores: (2908, 161, 166)\n",
            "Parâmetros: {'num_features': 30, 'feature_local_class': 'KeyNetHardNet', 'distance': 0.9, 'threshold': 0.5}\n",
            "Matches: (2053, 262, 1021)\n",
            "Scores: (2417, 45, 657)\n",
            "Parâmetros: {'num_features': 30, 'feature_local_class': 'HesAffNetHardNet', 'distance': 0.9, 'threshold': 0.5}\n",
            "Matches: (2627, 451, 447)\n",
            "Scores: (2858, 382, 216)\n",
            "Parâmetros: {'num_features': 30, 'feature_local_class': 'SIFTFeature', 'distance': 0.9, 'threshold': 0.5}\n",
            "Matches: (2608, 1696, 466)\n",
            "Scores: (2891, 1240, 183)\n",
            "Parâmetros: {'num_features': 30, 'feature_local_class': 'SIFTFeatureScaleSpace', 'distance': 0.9, 'threshold': 0.5}\n",
            "Matches: (2447, 3061, 627)\n",
            "Scores: (2826, 3028, 248)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from itertools import product\n",
        "\n",
        "def grid_search_pipeline(device, dataset_loader, param_grid):\n",
        "    all_results = []\n",
        "    transform_inspect = KA.AugmentationSequential(\n",
        "        # KA.RandomHorizontalFlip(p=0.5),\n",
        "        # KA.RandomVerticalFlip(p=0.5),\n",
        "        KA. RandomMedianBlur((3, 3), p = 1),\n",
        "        KA.RandomPerspective(0.3, p=0.75),\n",
        "        KA.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2, p=0.75),#brightness=0.5, contrast=0.5, saturation=0.5, hue=0.15, p=0.75\n",
        "        KA.RandomAffine(degrees=90, translate=(0.10, 0.10), scale=(0.90, 1.1), p=0.75),\n",
        "        same_on_batch=True,\n",
        "    )\n",
        "    for num_features, feature_local_class, distance, threshold in product(*param_grid.values()):\n",
        "        set_seed(42)\n",
        "        # Configuração específica do extrator de features com a classe e número de features\n",
        "        feature_extractor = feature_local_class(num_features, device=device)\n",
        "        SUM_MTP,SUM_MFP,SUM_MFN=0,0,0\n",
        "        SUM_STP,SUM_SFP,SUM_SFN=0,0,0\n",
        "        # Configurar a pipeline com os parâmetros atuais\n",
        "        pipeline = ImageComparisonPipeline(\n",
        "            pp, \n",
        "            feature_extractor, \n",
        "            DescriptorMatcher('snn', distance), \n",
        "            delaunayG, \n",
        "            floyd,\n",
        "        )\n",
        "        \n",
        "        # Executar a pipeline e registrar resultados para o batch atual\n",
        "        with medir_tempo():\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (original_batch, target) in enumerate(dataset_loader):\n",
        "                    original_batch = original_batch.to(device)\n",
        "                    referencia_batch, remaining_batch = torch.split(original_batch, original_batch.size(0) // 2, dim=0)\n",
        "                    inspection_images = transform_inspect(original_batch)\n",
        "\n",
        "                    # print(referencia_batch.shape,inspection_images.shape)\n",
        "                    matches, scores = pipeline.run(inspection_images, referencia_batch,threshold=threshold, device=device, log=None)#log='DEBUG','INFO'\n",
        "                    \n",
        "                    # print_table(matches)\n",
        "                    # print_table(scores)\n",
        "                    MTP, MFP, MFN = evaluate_matches(matches,threshold=4)#min de 4 pontos\n",
        "                    STP, SFP, SFN = evaluate_matches(scores,threshold=10)# min de 4 correspondencia (3,7)\n",
        "                    SUM_MTP += MTP\n",
        "                    SUM_MFP += MFP\n",
        "                    SUM_MFN += MFN\n",
        "                    \n",
        "                    SUM_STP += STP\n",
        "                    SUM_SFP += SFP\n",
        "                    SUM_SFN += SFN\n",
        "                    \n",
        "                    # print((SUM_MTP,SUM_MFP,SUM_MFN),(SUM_STP,SUM_SFP,SUM_SFN))\n",
        "                    free_memory()\n",
        "                    # break\n",
        "                result = {\n",
        "                    'params': {\n",
        "                        'num_features': num_features,\n",
        "                        'feature_local_class': feature_local_class.__name__,\n",
        "                        'distance': distance,\n",
        "                        'threshold': threshold\n",
        "                    },\n",
        "                    'matches': (SUM_MTP,SUM_MFP,SUM_MFN),\n",
        "                    'scores': (SUM_STP,SUM_SFP,SUM_SFN),\n",
        "                }\n",
        "                print(result)\n",
        "                all_results.append(result)         \n",
        "    return all_results\n",
        "\n",
        "# Grid de parâmetros\n",
        "param_grid = {\n",
        "    'num_features': [30],#5,10,20,30\n",
        "    'feature_local': [GFTTAffNetHardNet,GFTTFeatureSosNet, KeyNetHardNet,HesAffNetHardNet,SIFTFeature, SIFTFeatureScaleSpace],#GFTTAffNetHardNet,GFTTFeatureSosNet, KeyNetHardNet,HesAffNetHardNet,SIFTFeature, SIFTFeatureScaleSpace\n",
        "    'distance': [0.9],#defaul 0.8, bom 0.9 e 1.75#8,1.0,1.5\n",
        "    'threshold': [0.5]#0.5,0.05\n",
        "}\n",
        "\n",
        "# Supondo que 'flowers_loader' seja o DataLoader do seu dataset\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device \",device)\n",
        "all_results = grid_search_pipeline(device, some_loader, param_grid)\n",
        "for result in all_results:\n",
        "    print(\"Parâmetros:\", result['params'])\n",
        "    print(\"Matches:\", result['matches'])\n",
        "    print(\"Scores:\", result['scores'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-----------------------+----------+-----------+--------------------------+--------------------------+\n",
            "| Num Features |  Feature Local Class  | Distance | Threshold |         Matches          |          Scores          |\n",
            "+--------------+-----------------------+----------+-----------+--------------------------+--------------------------+\n",
            "|      30      |   GFTTAffNetHardNet   |   0.9    |    0.5    | [TP:2701,FP:441,FN:373]  | [TP:2894,FP:406,FN:180]  |\n",
            "|              |                       |          |           | [P:0.86,R:0.88,F1:0.87]  | [P:0.88,R:0.94,F1:0.91]  |\n",
            "|              |                       |          |           |                          |                          |\n",
            "|      30      |   GFTTFeatureSosNet   |   0.9    |    0.5    | [TP:2746,FP:346,FN:328]  | [TP:2908,FP:161,FN:166]  |\n",
            "|              |                       |          |           | [P:0.89,R:0.89,F1:0.89]  | [P:0.95,R:0.95,F1:0.95]  |\n",
            "|              |                       |          |           |                          |                          |\n",
            "|      30      |     KeyNetHardNet     |   0.9    |    0.5    | [TP:2053,FP:262,FN:1021] |  [TP:2417,FP:45,FN:657]  |\n",
            "|              |                       |          |           | [P:0.89,R:0.67,F1:0.76]  | [P:0.98,R:0.79,F1:0.87]  |\n",
            "|              |                       |          |           |                          |                          |\n",
            "|      30      |    HesAffNetHardNet   |   0.9    |    0.5    | [TP:2627,FP:451,FN:447]  | [TP:2858,FP:382,FN:216]  |\n",
            "|              |                       |          |           | [P:0.85,R:0.85,F1:0.85]  | [P:0.88,R:0.93,F1:0.91]  |\n",
            "|              |                       |          |           |                          |                          |\n",
            "|      30      |      SIFTFeature      |   0.9    |    0.5    | [TP:2608,FP:1696,FN:466] | [TP:2891,FP:1240,FN:183] |\n",
            "|              |                       |          |           | [P:0.61,R:0.85,F1:0.71]  | [P:0.70,R:0.94,F1:0.80]  |\n",
            "|              |                       |          |           |                          |                          |\n",
            "|      30      | SIFTFeatureScaleSpace |   0.9    |    0.5    | [TP:2447,FP:3061,FN:627] | [TP:2826,FP:3028,FN:248] |\n",
            "|              |                       |          |           | [P:0.44,R:0.80,F1:0.57]  | [P:0.48,R:0.92,F1:0.63]  |\n",
            "|              |                       |          |           |                          |                          |\n",
            "+--------------+-----------------------+----------+-----------+--------------------------+--------------------------+\n"
          ]
        }
      ],
      "source": [
        "def generate_metrics_output(TP, FP, FN):\n",
        "    \"\"\"\n",
        "    Gera uma string formatada com os valores de TP, FP, FN, Precisão (P), Recall (R) e F1-score (F1).\n",
        "\n",
        "    Args:\n",
        "    TP (int): Número de verdadeiros positivos.\n",
        "    FP (int): Número de falsos positivos.\n",
        "    FN (int): Número de falsos negativos.\n",
        "\n",
        "    Returns:\n",
        "    str: Uma string formatada contendo as métricas.\n",
        "    \"\"\"\n",
        "    # Calcular Precisão, Recall e F1-score\n",
        "    P = TP / (TP + FP) if TP + FP > 0 else 0  # Precisão\n",
        "    R = TP / (TP + FN) if TP + FN > 0 else 0  # Recall\n",
        "    F1 = 2 * (P * R) / (P + R) if P + R > 0 else 0  # F1-score\n",
        "\n",
        "    # Formatar e retornar a string de saída\n",
        "    return \"[TP:{},FP:{},FN:{}]\\n[P:{:.2f},R:{:.2f},F1:{:.2f}]\\n\".format(TP, FP, FN, P, R, F1)\n",
        "\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "# Criando uma tabela com prettytable\n",
        "table = PrettyTable()\n",
        "\n",
        "# Adicionando cabeçalhos à tabela\n",
        "table.field_names = [\"Num Features\", \"Feature Local Class\", \"Distance\", \"Threshold\", \"Matches\", \"Scores\"]\n",
        "\n",
        "# Adicionando as linhas com os resultados\n",
        "for result in all_results:\n",
        "    params = result['params']\n",
        "    SUM_MTP,SUM_MFP,SUM_MFN = result['matches']\n",
        "    SUM_STP,SUM_SFP,SUM_SFN = result['scores']\n",
        "    \n",
        "    table.add_row([params['num_features'], params['feature_local_class'], params['distance'], params['threshold'], generate_metrics_output(SUM_MTP,SUM_MFP,SUM_MFN), generate_metrics_output(SUM_STP,SUM_SFP,SUM_SFN)])\n",
        "\n",
        "# Imprimindo a tabela\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "| Num Features |  Feature Local Class  | Distance | Threshold |         Matches         |          Scores         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "|      30      |   GFTTAffNetHardNet   |   0.9    |    0.5    |   [TP:444,FP:56,FN:66]  |   [TP:486,FP:46,FN:24]  |\n",
        "|              |                       |          |           | [P:0.89,R:0.87,F1:0.88] | [P:0.91,R:0.95,F1:0.93] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |   GFTTFeatureSosNet   |   0.9    |    0.5    |   [TP:451,FP:46,FN:59]  |   [TP:489,FP:27,FN:21]  |\n",
        "|              |                       |          |           | [P:0.91,R:0.88,F1:0.90] | [P:0.95,R:0.96,F1:0.95] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |     KeyNetHardNet     |   0.9    |    0.5    |  [TP:348,FP:31,FN:162]  |   [TP:408,FP:4,FN:102]  |\n",
        "|              |                       |          |           | [P:0.92,R:0.68,F1:0.78] | [P:0.99,R:0.80,F1:0.89] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |    HesAffNetHardNet   |   0.9    |    0.5    |  [TP:409,FP:63,FN:101]  |   [TP:469,FP:59,FN:41]  |\n",
        "|              |                       |          |           | [P:0.87,R:0.80,F1:0.83] | [P:0.89,R:0.92,F1:0.90] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.9    |    0.5    |  [TP:450,FP:312,FN:60]  |  [TP:496,FP:191,FN:14]  |\n",
        "|              |                       |          |           | [P:0.59,R:0.88,F1:0.71] | [P:0.72,R:0.97,F1:0.83] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.9    |    0.5    |  [TP:432,FP:506,FN:78]  |  [TP:489,FP:503,FN:21]  |\n",
        "|              |                       |          |           | [P:0.46,R:0.85,F1:0.60] | [P:0.49,R:0.96,F1:0.65] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.8    |    0.5    |   [TP:425,FP:12,FN:85]  |   [TP:474,FP:2,FN:36]   |\n",
        "|              |                       |          |           | [P:0.97,R:0.83,F1:0.90] | [P:1.00,R:0.93,F1:0.96] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.8    |    0.5    |   [TP:445,FP:38,FN:65]  |   [TP:488,FP:10,FN:22]  |\n",
        "|              |                       |          |           | [P:0.92,R:0.87,F1:0.90] | [P:0.98,R:0.96,F1:0.97] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "| Num Features |  Feature Local Class  | Distance | Threshold |         Matches         |          Scores         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "|      30      |   GFTTAffNetHardNet   |   0.9    |    0.5    |   [TP:23,FP:3,FN:154]   |   [TP:39,FP:0,FN:138]   |\n",
        "|              |                       |          |           | [P:0.88,R:0.13,F1:0.23] | [P:1.00,R:0.22,F1:0.36] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |   GFTTFeatureSosNet   |   0.9    |    0.5    |   [TP:29,FP:0,FN:148]   |   [TP:46,FP:1,FN:131]   |\n",
        "|              |                       |          |           | [P:1.00,R:0.16,F1:0.28] | [P:0.98,R:0.26,F1:0.41] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |     KeyNetHardNet     |   0.9    |    0.5    |    [TP:0,FP:3,FN:177]   |    [TP:5,FP:0,FN:172]   |\n",
        "|              |                       |          |           | [P:0.00,R:0.00,F1:0.00] | [P:1.00,R:0.03,F1:0.05] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |    HesAffNetHardNet   |   0.9    |    0.5    |   [TP:29,FP:4,FN:148]   |   [TP:43,FP:1,FN:134]   |\n",
        "|              |                       |          |           | [P:0.88,R:0.16,F1:0.28] | [P:0.98,R:0.24,F1:0.39] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.9    |    0.5    |   [TP:15,FP:57,FN:162]  |   [TP:44,FP:0,FN:133]   |\n",
        "|              |                       |          |           | [P:0.21,R:0.08,F1:0.12] | [P:1.00,R:0.25,F1:0.40] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.9    |    0.5    |   [TP:4,FP:131,FN:173]  |    [TP:9,FP:0,FN:168]   |\n",
        "|              |                       |          |           | [P:0.03,R:0.02,F1:0.03] | [P:1.00,R:0.05,F1:0.10] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.8    |    0.5    |    [TP:6,FP:0,FN:171]   |   [TP:34,FP:0,FN:143]   |\n",
        "|              |                       |          |           | [P:1.00,R:0.03,F1:0.07] | [P:1.00,R:0.19,F1:0.32] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.8    |    0.5    |   [TP:1,FP:14,FN:176]   |    [TP:8,FP:0,FN:169]   |\n",
        "|              |                       |          |           | [P:0.07,R:0.01,F1:0.01] | [P:1.00,R:0.05,F1:0.09] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
