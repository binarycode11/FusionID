{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binarycode11/PapyrusTech/blob/sibgrapi/GridSearch_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m7qDTBLJ0voC"
      },
      "outputs": [],
      "source": [
        "#!pip install kornia\n",
        "# !pip install kornia_moons --no-deps\n",
        "# !pip install kornia_moons\n",
        "\n",
        "\n",
        "# import os\n",
        "# %cd /content/\n",
        "# folder_path = '/content/PapyrusTech'\n",
        "# branch = \"sibgrapi\"\n",
        "\n",
        "# if os.path.exists(folder_path):\n",
        "#     # Apaga todo o conteúdo da pasta\n",
        "#     !rm -rf {folder_path}/\n",
        "#     print(f\"Todo o conteúdo da pasta {folder_path} foi apagado.\")\n",
        "# else:\n",
        "#     print(f\"A pasta {folder_path} não existe.\")\n",
        "\n",
        "# from google.colab import userdata\n",
        "# token = userdata.get('token2')\n",
        "# # Clonar o repositório privado usando o token\n",
        "# !git clone -b {branch} https://{token}@github.com/binarycode11/PapyrusTech.git\n",
        "\n",
        "# %cd {folder_path}\n",
        "# !ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccx4czDmT1ZW",
        "outputId": "1ca5f299-b3de-473e-92de-22eca287e00b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exemplo de Tempo: 0.05012007100003757 segundos\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from kornia.utils import tensor_to_image\n",
        "from typing import Dict, Tuple, List\n",
        "from kornia.feature import LocalFeatureMatcher, GFTTAffNetHardNet, DescriptorMatcher,KeyNetHardNet,SIFTFeatureScaleSpace,SIFTFeature,HesAffNetHardNet\n",
        "from kornia.feature import LocalFeature, LAFDescriptor, MultiResolutionDetector,ScaleSpaceDetector, SOSNet,HardNet\n",
        "from kornia.feature import CornerHarris, CornerGFTT, PassLAF, LAFOrienter, LAFAffNetShapeEstimator\n",
        "\n",
        "from utils import (\n",
        "    free_memory,  # Função para liberar memória coletando objetos não utilizados e esvaziando o cache da GPU se disponível\n",
        "    evaluate_matches,  # Função para avaliar correspondências entre conjuntos de referência e inspeção, retornando verdadeiros positivos, falsos positivos e falsos negativos\n",
        "    set_seed,  # Função para configurar a semente e garantir a reprodutibilidade dos experimentos\n",
        "    medir_tempo,  # Context Manager para medir e imprimir o tempo de execução de um bloco de código\n",
        "    plot_image_with_keypoints,  # Função para plotar uma imagem e seus keypoints\n",
        "    plot_tensor,  # Função para plotar um tensor PyTorch como uma imagem\n",
        "    print_table,  # Função para imprimir uma matriz em formato tabular\n",
        "    MyDrawMatcher  # Classe para desenhar correspondências entre imagens utilizando Kornia\n",
        ")\n",
        "set_seed(42)\n",
        "\n",
        "# Importa classes e módulos do pacote 'experiments'\n",
        "from experiments import (\n",
        "    PreprocessPipeline,  # Classe que implementa a interface IPreprocessor para pré-processamento de imagens, incluindo normalização, redimensionamento e conversão para escala de cinza\n",
        "    DelaunayGraph,  # Classe que implementa a interface IGlobalFeatureStructurer para estruturar features globais em um grafo usando triangulação Delaunay\n",
        "    FloydWarshall,  # Classe que implementa a interface IGlobalMatcher para comparar similaridade global de features em grafos usando o algoritmo de Floyd-Warshall\n",
        "    WoodsDataset,\n",
        "    GenericDataset\n",
        ")\n",
        "\n",
        "# Exemplo de uso do Context Manager para medir o tempo de execução de um bloco de código\n",
        "with medir_tempo(\"Exemplo de Tempo\"):\n",
        "    # Loop para realizar um milhão de iterações como exemplo\n",
        "    for i in range(1_000_000):\n",
        "        pass  # Placeholder para o código a ser executado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC3mt__LJNgM",
        "outputId": "83b0e10d-2e4a-431e-c19c-3523a6be9855"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device cuda\n",
            "Total de elementos no dataset: 8188 total batch: 82\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class ImageComparisonPipeline:\n",
        "    # __slots__ = ['preprocessor', 'local_feature', 'descriptor_matcher', 'global_structurer', 'global_matcher']\n",
        "\n",
        "    def __init__(self, preprocessor=None, local_feature: LocalFeature = None, descriptor_matcher: DescriptorMatcher = None, global_structurer=None, global_matcher=None):\n",
        "        self.preprocessor = preprocessor\n",
        "        self.local_feature = local_feature\n",
        "        self.descriptor_matcher_ablation = descriptor_matcher\n",
        "        self.descriptor_matcher_fixed=  DescriptorMatcher('snn', self.descriptor_matcher_ablation.th)\n",
        "        self.global_structurer = global_structurer\n",
        "        self.global_matcher = global_matcher\n",
        "\n",
        "\n",
        "    def process_global(self, out,images,is_plot=False):\n",
        "        matricesAdj = []\n",
        "\n",
        "        for index in (0, 1):\n",
        "            pts = out[f'keypoints{index}'][out['matches'][:, index]].cpu().detach().numpy()\n",
        "            desc = out[f'descriptors{index}'][out['matches'][:, index]].cpu().detach().numpy()\n",
        "            matrixAdj, _ = self.global_structurer(pts, desc)\n",
        "            matricesAdj.append(matrixAdj)\n",
        "            if is_plot:\n",
        "                img = tensor_to_image(images[index].squeeze())\n",
        "                DelaunayGraph.plot_delaunay(pts,_,img=img)\n",
        "        return matricesAdj\n",
        "\n",
        "    def run(self, inspection_images: torch.Tensor, reference_images: torch.Tensor,threshold=0.1, log=None,device=torch.device('cpu')) -> Dict[Tuple[int, int], float]:\n",
        "        if not all([self.preprocessor, self.local_feature, self.descriptor_matcher_ablation, self.global_structurer, self.global_matcher]):\n",
        "            raise ValueError(\"Pipeline components are not fully set.\")\n",
        "        n,m = inspection_images.shape[0],reference_images.shape[0]\n",
        "        scores = np.zeros((n, m))\n",
        "        count_match = np.zeros((n, m))\n",
        "        myDraw =MyDrawMatcher()\n",
        "        cache_reference = {}\n",
        "\n",
        "        for i_index, i_image in enumerate(inspection_images):\n",
        "            lafs0, responses0, descriptors0 = self.local_feature(i_image[:1][None])\n",
        "            for r_index, r_image in enumerate(reference_images):\n",
        "                if r_index not in cache_reference:\n",
        "                    lafs1, responses1, descriptors1 = self.local_feature(r_image[:1][None])\n",
        "                    cache_reference[r_index] = (lafs1, responses1, descriptors1)\n",
        "                else:\n",
        "                    lafs1, responses1, descriptors1 = cache_reference[r_index]\n",
        "\n",
        "                distance_ablation, matches_ablation = self.descriptor_matcher_ablation(descriptors0[0], descriptors1[0])# ablation\n",
        "                distance, matches = self.descriptor_matcher_fixed(descriptors0[0], descriptors1[0])\n",
        "                out = {\n",
        "                \"keypoints0\": lafs0[0, :, :, 2].data,#[N, 2])\n",
        "                \"keypoints1\": lafs1[0, :, :, 2].data,#[N, 2])\n",
        "                \"lafs0\": lafs0,#[1, N, 2, 3]\n",
        "                \"lafs1\": lafs1,#[1, N, 2, 3]\n",
        "                \"descriptors0\": descriptors0[0],#[N, 128])\n",
        "                \"descriptors1\": descriptors1[0],#[N, 128])\n",
        "                \"matches\": matches,#[M, 2])\n",
        "                }\n",
        "\n",
        "\n",
        "                #ignora quando existem poucos pontos, pois diminui a confianca(global)\n",
        "                if(matches.shape[0]>=3):\n",
        "                    try:\n",
        "                        is_plot= False\n",
        "                        # if  i_index==3 and r_index in [3,12]:\n",
        "                        #     print(\"({},{})=>*\".format(i_index,r_index))\n",
        "                        #     is_plot= True\n",
        "                        matricesAdj = self.process_global(out,images=[i_image,r_image],is_plot=is_plot)\n",
        "                        score = self.global_matcher(*matricesAdj, threshold=threshold)\n",
        "                    except Exception as e:\n",
        "                        score = 0   # possui poucos pontos\n",
        "                else:\n",
        "                   score = 0\n",
        "\n",
        "                #ignora quando existem poucos pontos, pois diminui a confianca(local)\n",
        "                num_match = matches_ablation.shape[0]\n",
        "                if num_match<8:\n",
        "                    num_match= 0\n",
        "\n",
        "                # if log is not None and log in ('DEBUG') and i_index == r_index and i_index%20==0:\n",
        "                if log is not None and log in ('DEBUG') and ( i_index==3 and r_index in [3,12]):\n",
        "                    print(i_index,r_index ,out['keypoints0'].shape,out['descriptors0'].shape,out['matches'].shape,)\n",
        "                    temp = out.copy()\n",
        "                    temp['matches']=matches_ablation\n",
        "                    myDraw(i_image.cpu(), r_image.cpu(),temp)\n",
        "\n",
        "                count_match[i_index, r_index] = num_match # avaliacao pelo quantidade matching\n",
        "                scores[i_index, r_index] = score # avaliacao pela correspondencia local+global\n",
        "\n",
        "        if log is not None and log in ('INFO'):\n",
        "            print_table(count_match)\n",
        "            print(\"count_match : \",evaluate_matches(count_match,8))\n",
        "            print_table(scores)\n",
        "            print(\"scores : \",evaluate_matches(scores,8))\n",
        "\n",
        "        return count_match,scores\n",
        "\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import kornia.augmentation as KA\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "\n",
        "transform_original = transforms.Compose([\n",
        "    transforms.Resize((180, 180)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device',device)\n",
        "someDataset = GenericDataset(root=\"./data/flowers-102/jpg/\",transform=transform_original, limit_train=1.0)\n",
        "# someDataset = GenericDataset(root=\"./data/woods/\",transform=transform_original, limit_train=1.0)\n",
        "# Encontre o primeiro número par abaixo de total_size\n",
        "total_size = len(someDataset)\n",
        "if total_size % 2 != 0:\n",
        "    total_size -= 1\n",
        "indices = np.arange(total_size)\n",
        "subset = Subset(someDataset, indices)\n",
        "\n",
        "some_loader = DataLoader(subset, batch_size=500, shuffle=True,)\n",
        "total_elements = len(some_loader.dataset)\n",
        "total_batches = len(some_loader)\n",
        "print(f'Total de elementos no dataset: {total_elements} total batch: {total_batches}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GQAD5wLWl4H5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from kornia.feature import LocalFeature, LAFDescriptor, MultiResolutionDetector,SOSNet\n",
        "from kornia.feature import CornerGFTT, PassLAF, LAFOrienter, LAFAffNetShapeEstimator\n",
        "from kornia.feature.scale_space_detector import get_default_detector_config\n",
        "# Assuming SOSNet can be correctly imported as shown before; adjust if needed.\n",
        "\n",
        "\n",
        "class GFTTFeatureSosNet(LocalFeature): #0.9    |   0.005\n",
        "    \"\"\"Convenience module, which implements GFTT detector + SOSNet descriptor.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_features: int = 200,\n",
        "        upright: bool = False,\n",
        "        device: torch.device = torch.device(\"cpu\"),\n",
        "        config: dict = None,\n",
        "    ) -> None:\n",
        "        if config is None:\n",
        "            config = get_default_detector_config()\n",
        "        detector = MultiResolutionDetector(\n",
        "            CornerGFTT(),\n",
        "            num_features,\n",
        "            config,\n",
        "            ori_module=PassLAF() if upright else LAFOrienter(19),\n",
        "            aff_module=LAFAffNetShapeEstimator(preserve_orientation=upright).eval(),  # Usa `upright` para definir `preserve_orientation`\n",
        "        ).to(device)\n",
        "\n",
        "        # Initialize your descriptor (e.g., SOSNet) as before\n",
        "        # Example with SOSNet - replace with actual initialization if different\n",
        "        sosnet32 = SOSNet(pretrained=True)  # Placeholder; adjust according to actual SOSNet import\n",
        "        sosnet32 = sosnet32.to(device).eval()\n",
        "\n",
        "        descriptor = LAFDescriptor(sosnet32, patch_size=32, grayscale_descriptor=True).to(device)\n",
        "\n",
        "        super().__init__(detector, descriptor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "733aOY76l4H6"
      },
      "outputs": [],
      "source": [
        "pp = PreprocessPipeline()\n",
        "delaunayG = DelaunayGraph()\n",
        "floyd = FloydWarshall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device  cuda:0\n",
            "{'params': {'num_features': 30, 'feature_local_class': 'SIFTFeature', 'distance': 0.8, 'threshold': 0.5}, 'matches': (3101, 66, 993), 'scores': (3543, 1, 551)}\n",
            "Tempo de execução: 688.903735335 segundos\n",
            "Tempo de execução: 171.74490726299973 segundos\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice \u001b[39m\u001b[38;5;124m\"\u001b[39m,device)\n\u001b[0;32m---> 80\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msome_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_results:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParâmetros:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
            "Cell \u001b[0;32mIn[6], line 39\u001b[0m, in \u001b[0;36mgrid_search_pipeline\u001b[0;34m(device, dataset_loader, param_grid)\u001b[0m\n\u001b[1;32m     36\u001b[0m inspection_images \u001b[38;5;241m=\u001b[39m transform_inspect(original_batch)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# print(referencia_batch.shape,inspection_images.shape)\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m matches, scores \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43minspection_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreferencia_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#log='DEBUG','INFO'\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# print_table(matches)\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# print_table(scores)\u001b[39;00m\n\u001b[1;32m     43\u001b[0m MTP, MFP, MFN \u001b[38;5;241m=\u001b[39m evaluate_matches(matches,threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;66;03m#min de 4 pontos\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36mImageComparisonPipeline.run\u001b[0;34m(self, inspection_images, reference_images, threshold, log, device)\u001b[0m\n\u001b[1;32m     33\u001b[0m cache_reference \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i_index, i_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(inspection_images):\n\u001b[0;32m---> 36\u001b[0m     lafs0, responses0, descriptors0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi_image\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r_index, r_image \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(reference_images):\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m r_index \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cache_reference:\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/kornia/feature/integrated.py:138\u001b[0m, in \u001b[0;36mLocalFeature.forward\u001b[0;34m(self, img, mask)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: Tensor, mask: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Tensor, Tensor, Tensor]:\n\u001b[1;32m    127\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;124;03m        img: image to extract features with shape :math:`(B,C,H,W)`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m        - Local descriptors of shape :math:`(B,N,D)` where :math:`D` is descriptor size.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     lafs, responses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     lafs \u001b[38;5;241m=\u001b[39m scale_laf(lafs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling_coef)\n\u001b[1;32m    140\u001b[0m     descs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdescriptor(img, lafs)\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/kornia/feature/scale_space_detector.py:224\u001b[0m, in \u001b[0;36mScaleSpaceDetector.forward\u001b[0;34m(self, img, mask)\u001b[0m\n\u001b[1;32m    222\u001b[0m responses, lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetect(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features, mask)\n\u001b[1;32m    223\u001b[0m lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maff(lafs, img)\n\u001b[0;32m--> 224\u001b[0m lafs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mori\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlafs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lafs, responses\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/kornia/feature/orientation.py:233\u001b[0m, in \u001b[0;36mLAFOrienter.forward\u001b[0;34m(self, laf, img)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size of laf and img should be the same. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlaf\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    232\u001b[0m B, N \u001b[38;5;241m=\u001b[39m laf\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m--> 233\u001b[0m patches: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[43mextract_patches_from_pyramid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    236\u001b[0m angles_radians: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle_detector(patches)\u001b[38;5;241m.\u001b[39mview(B, N)\n\u001b[1;32m    237\u001b[0m prev_angle \u001b[38;5;241m=\u001b[39m get_laf_orientation(laf)\u001b[38;5;241m.\u001b[39mview_as(angles_radians)\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/kornia/feature/laf.py:450\u001b[0m, in \u001b[0;36mextract_patches_from_pyramid\u001b[0;34m(img, laf, PS, normalize_lafs_before_extraction)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m we_are_in_business:\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m     cur_img \u001b[38;5;241m=\u001b[39m \u001b[43mpyrdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m     cur_pyr_level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/kornia/geometry/transform/pyramid.py:252\u001b[0m, in \u001b[0;36mpyrdown\u001b[0;34m(input, border_type, align_corners, factor)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpyrdown\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, border_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflect\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, factor: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    231\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Blur a tensor and downsamples it.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    .. image:: _static/img/pyrdown.png\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;124;03m                  [ 9.7500, 11.2500]]]])\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[43mKORNIA_CHECK_SHAPE\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mH\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     kernel: Tensor \u001b[38;5;241m=\u001b[39m _get_pyramid_gaussian_kernel()\n\u001b[1;32m    255\u001b[0m     _, _, height, width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n",
            "File \u001b[0;32m~/Documentos/python/PapyrusTech/.venv/lib/python3.11/site-packages/kornia/core/check.py:70\u001b[0m, in \u001b[0;36mKORNIA_CHECK_SHAPE\u001b[0;34m(x, shape, raises)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_shape_to_check)):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# The voodoo below is because torchscript does not like\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# that dim can be both int and str\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     dim_: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m shape_to_check[i]\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dim_\u001b[38;5;241m.\u001b[39misnumeric():\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from itertools import product\n",
        "\n",
        "def grid_search_pipeline(device, dataset_loader, param_grid):\n",
        "    all_results = []\n",
        "    transform_inspect = KA.AugmentationSequential(\n",
        "        # KA.RandomHorizontalFlip(p=0.5),\n",
        "        # KA.RandomVerticalFlip(p=0.5),\n",
        "        KA. RandomMedianBlur((3, 3), p = 1),\n",
        "        KA.RandomPerspective(0.3, p=0.75),\n",
        "        KA.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2, p=0.75),#brightness=0.5, contrast=0.5, saturation=0.5, hue=0.15, p=0.75\n",
        "        KA.RandomAffine(degrees=90, translate=(0.10, 0.10), scale=(0.90, 1.1), p=0.75),\n",
        "        same_on_batch=True,\n",
        "    )\n",
        "    for num_features, feature_local_class, distance, threshold in product(*param_grid.values()):\n",
        "        set_seed(42)\n",
        "        # Configuração específica do extrator de features com a classe e número de features\n",
        "        feature_extractor = feature_local_class(num_features, device=device)\n",
        "        SUM_MTP,SUM_MFP,SUM_MFN=0,0,0\n",
        "        SUM_STP,SUM_SFP,SUM_SFN=0,0,0\n",
        "        # Configurar a pipeline com os parâmetros atuais\n",
        "        pipeline = ImageComparisonPipeline(\n",
        "            pp,\n",
        "            feature_extractor,\n",
        "            DescriptorMatcher('snn', distance),\n",
        "            delaunayG,\n",
        "            floyd,\n",
        "        )\n",
        "\n",
        "        # Executar a pipeline e registrar resultados para o batch atual\n",
        "        with medir_tempo():\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (original_batch, target) in enumerate(dataset_loader):\n",
        "                    original_batch = original_batch.to(device)\n",
        "                    referencia_batch, remaining_batch = torch.split(original_batch, original_batch.size(0) // 2, dim=0)\n",
        "                    inspection_images = transform_inspect(original_batch)\n",
        "\n",
        "                    # print(referencia_batch.shape,inspection_images.shape)\n",
        "                    matches, scores = pipeline.run(inspection_images, referencia_batch,threshold=threshold, device=device, log=None)#log='DEBUG','INFO'\n",
        "\n",
        "                    # print_table(matches)\n",
        "                    # print_table(scores)\n",
        "                    MTP, MFP, MFN = evaluate_matches(matches,threshold=4)#min de 4 pontos\n",
        "                    STP, SFP, SFN = evaluate_matches(scores,threshold=10)# min de 4 correspondencia (3,7)\n",
        "                    SUM_MTP += MTP\n",
        "                    SUM_MFP += MFP\n",
        "                    SUM_MFN += MFN\n",
        "\n",
        "                    SUM_STP += STP\n",
        "                    SUM_SFP += SFP\n",
        "                    SUM_SFN += SFN\n",
        "\n",
        "                    # print((SUM_MTP,SUM_MFP,SUM_MFN),(SUM_STP,SUM_SFP,SUM_SFN))\n",
        "                    free_memory()\n",
        "                    # break\n",
        "                result = {\n",
        "                    'params': {\n",
        "                        'num_features': num_features,\n",
        "                        'feature_local_class': feature_local_class.__name__,\n",
        "                        'distance': distance,\n",
        "                        'threshold': threshold\n",
        "                    },\n",
        "                    'matches': (SUM_MTP,SUM_MFP,SUM_MFN),\n",
        "                    'scores': (SUM_STP,SUM_SFP,SUM_SFN),\n",
        "                }\n",
        "                print(result)\n",
        "                all_results.append(result)\n",
        "    return all_results\n",
        "\n",
        "# Grid de parâmetros\n",
        "param_grid = {\n",
        "    'num_features': [30],#5,10,20,30\n",
        "    'feature_local': [GFTTAffNetHardNet],#GFTTAffNetHardNet,GFTTFeatureSosNet, KeyNetHardNet,HesAffNetHardNet,SIFTFeature, SIFTFeatureScaleSpace\n",
        "    'distance': [0.9],#defaul 0.8, bom 0.9 e 1.75#8,1.0,1.5\n",
        "    'threshold': [0.5]#0.5,0.05\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device \",device)\n",
        "all_results = grid_search_pipeline(device, some_loader, param_grid)\n",
        "for result in all_results:\n",
        "    print(\"Parâmetros:\", result['params'])\n",
        "    print(\"Matches:\", result['matches'])\n",
        "    print(\"Scores:\", result['scores'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_metrics_output(TP, FP, FN):\n",
        "    \"\"\"\n",
        "    Gera uma string formatada com os valores de TP, FP, FN, Precisão (P), Recall (R) e F1-score (F1).\n",
        "\n",
        "    Args:\n",
        "    TP (int): Número de verdadeiros positivos.\n",
        "    FP (int): Número de falsos positivos.\n",
        "    FN (int): Número de falsos negativos.\n",
        "\n",
        "    Returns:\n",
        "    str: Uma string formatada contendo as métricas.\n",
        "    \"\"\"\n",
        "    # Calcular Precisão, Recall e F1-score\n",
        "    P = TP / (TP + FP) if TP + FP > 0 else 0  # Precisão\n",
        "    R = TP / (TP + FN) if TP + FN > 0 else 0  # Recall\n",
        "    F1 = 2 * (P * R) / (P + R) if P + R > 0 else 0  # F1-score\n",
        "\n",
        "    # Formatar e retornar a string de saída\n",
        "    return \"[TP:{},FP:{},FN:{}]\\n[P:{:.2f},R:{:.2f},F1:{:.2f}]\\n\".format(TP, FP, FN, P, R, F1)\n",
        "\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "# Criando uma tabela com prettytable\n",
        "table = PrettyTable()\n",
        "\n",
        "# Adicionando cabeçalhos à tabela\n",
        "table.field_names = [\"Num Features\", \"Feature Local Class\", \"Distance\", \"Threshold\", \"Matches\", \"Scores\"]\n",
        "\n",
        "# Adicionando as linhas com os resultados\n",
        "for result in all_results:\n",
        "    params = result['params']\n",
        "    SUM_MTP,SUM_MFP,SUM_MFN = result['matches']\n",
        "    SUM_STP,SUM_SFP,SUM_SFN = result['scores']\n",
        "\n",
        "    table.add_row([params['num_features'], params['feature_local_class'], params['distance'], params['threshold'], generate_metrics_output(SUM_MTP,SUM_MFP,SUM_MFN), generate_metrics_output(SUM_STP,SUM_SFP,SUM_SFN)])\n",
        "\n",
        "# Imprimindo a tabela\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFY3wZ_tl4H8"
      },
      "source": [
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "| Num Features |  Feature Local Class  | Distance | Threshold |         Matches         |          Scores         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "|      30      |   GFTTAffNetHardNet   |   0.9    |    0.5    |   [TP:444,FP:56,FN:66]  |   [TP:486,FP:46,FN:24]  |\n",
        "|              |                       |          |           | [P:0.89,R:0.87,F1:0.88] | [P:0.91,R:0.95,F1:0.93] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |   GFTTFeatureSosNet   |   0.9    |    0.5    |   [TP:451,FP:46,FN:59]  |   [TP:489,FP:27,FN:21]  |\n",
        "|              |                       |          |           | [P:0.91,R:0.88,F1:0.90] | [P:0.95,R:0.96,F1:0.95] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |     KeyNetHardNet     |   0.9    |    0.5    |  [TP:348,FP:31,FN:162]  |   [TP:408,FP:4,FN:102]  |\n",
        "|              |                       |          |           | [P:0.92,R:0.68,F1:0.78] | [P:0.99,R:0.80,F1:0.89] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |    HesAffNetHardNet   |   0.9    |    0.5    |  [TP:409,FP:63,FN:101]  |   [TP:469,FP:59,FN:41]  |\n",
        "|              |                       |          |           | [P:0.87,R:0.80,F1:0.83] | [P:0.89,R:0.92,F1:0.90] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.9    |    0.5    |  [TP:450,FP:312,FN:60]  |  [TP:496,FP:191,FN:14]  |\n",
        "|              |                       |          |           | [P:0.59,R:0.88,F1:0.71] | [P:0.72,R:0.97,F1:0.83] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.9    |    0.5    |  [TP:432,FP:506,FN:78]  |  [TP:489,FP:503,FN:21]  |\n",
        "|              |                       |          |           | [P:0.46,R:0.85,F1:0.60] | [P:0.49,R:0.96,F1:0.65] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.8    |    0.5    |   [TP:425,FP:12,FN:85]  |   [TP:474,FP:2,FN:36]   |\n",
        "|              |                       |          |           | [P:0.97,R:0.83,F1:0.90] | [P:1.00,R:0.93,F1:0.96] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.8    |    0.5    |   [TP:445,FP:38,FN:65]  |   [TP:488,FP:10,FN:22]  |\n",
        "|              |                       |          |           | [P:0.92,R:0.87,F1:0.90] | [P:0.98,R:0.96,F1:0.97] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "| Num Features |  Feature Local Class  | Distance | Threshold |         Matches         |          Scores         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+\n",
        "|      30      |   GFTTAffNetHardNet   |   0.9    |    0.5    |   [TP:23,FP:3,FN:154]   |   [TP:39,FP:0,FN:138]   |\n",
        "|              |                       |          |           | [P:0.88,R:0.13,F1:0.23] | [P:1.00,R:0.22,F1:0.36] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |   GFTTFeatureSosNet   |   0.9    |    0.5    |   [TP:29,FP:0,FN:148]   |   [TP:46,FP:1,FN:131]   |\n",
        "|              |                       |          |           | [P:1.00,R:0.16,F1:0.28] | [P:0.98,R:0.26,F1:0.41] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |     KeyNetHardNet     |   0.9    |    0.5    |    [TP:0,FP:3,FN:177]   |    [TP:5,FP:0,FN:172]   |\n",
        "|              |                       |          |           | [P:0.00,R:0.00,F1:0.00] | [P:1.00,R:0.03,F1:0.05] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |    HesAffNetHardNet   |   0.9    |    0.5    |   [TP:29,FP:4,FN:148]   |   [TP:43,FP:1,FN:134]   |\n",
        "|              |                       |          |           | [P:0.88,R:0.16,F1:0.28] | [P:0.98,R:0.24,F1:0.39] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.9    |    0.5    |   [TP:15,FP:57,FN:162]  |   [TP:44,FP:0,FN:133]   |\n",
        "|              |                       |          |           | [P:0.21,R:0.08,F1:0.12] | [P:1.00,R:0.25,F1:0.40] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.9    |    0.5    |   [TP:4,FP:131,FN:173]  |    [TP:9,FP:0,FN:168]   |\n",
        "|              |                       |          |           | [P:0.03,R:0.02,F1:0.03] | [P:1.00,R:0.05,F1:0.10] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      |      SIFTFeature      |   0.8    |    0.5    |    [TP:6,FP:0,FN:171]   |   [TP:34,FP:0,FN:143]   |\n",
        "|              |                       |          |           | [P:1.00,R:0.03,F1:0.07] | [P:1.00,R:0.19,F1:0.32] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "|      30      | SIFTFeatureScaleSpace |   0.8    |    0.5    |   [TP:1,FP:14,FN:176]   |    [TP:8,FP:0,FN:169]   |\n",
        "|              |                       |          |           | [P:0.07,R:0.01,F1:0.01] | [P:1.00,R:0.05,F1:0.09] |\n",
        "|              |                       |          |           |                         |                         |\n",
        "+--------------+-----------------------+----------+-----------+-------------------------+-------------------------+"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
